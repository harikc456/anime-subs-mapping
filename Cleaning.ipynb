{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import operator\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from googletrans import Translator\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sentence_transformers import SentenceTransformer, util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "translator = Translator(service_urls=['translate.google.co.in'])\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "all_files = os.listdir(\"subs\")\n",
    "path = \"subs\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=6940.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "new_df = pd.DataFrame([])\n",
    "for file in tqdm(all_files):\n",
    "    file_path = os.path.join(path, file)\n",
    "    df = pd.read_csv(file_path)\n",
    "    df[\"file_name\"] = file\n",
    "    new_df = pd.concat([new_df, df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard(a, b):\n",
    "    a = set(a)\n",
    "    b = set(b)\n",
    "    c = a.intersection(b)\n",
    "    return float(len(c)) / (len(a) + len(b) - len(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing duplicates\n",
    "\n",
    "dedup_df = new_df.drop_duplicates()\n",
    "dedup_df = dedup_df.reset_index()\n",
    "\n",
    "# Removing mappings low quality semantic score \n",
    "\n",
    "dedup_df = dedup_df[dedup_df['semantic_score'] > 0.01]\n",
    "dedup_df = dedup_df[operator.and_(dedup_df['semantic_score'] > 0.2,  dedup_df['score'] > 0.2)]\n",
    "\n",
    "# Removing en_text with less than 3 characters\n",
    "\n",
    "dedup_df = dedup_df[dedup_df['en_text'].map(str).map(len) > 3]\n",
    "\n",
    "# Remove words inside {} and <> in jp_text and en_text\n",
    "\n",
    "dedup_df['jp_text'] = [re.sub(r\"{.*}\", \"\", x) for x in dedup_df['jp_text']]\n",
    "dedup_df['en_text'] = [re.sub(r\"{.*}\", \"\", x) for x in dedup_df['en_text']]\n",
    "dedup_df['jp_text'] = [re.sub(r\"<.*>\", \"\", x) for x in dedup_df['jp_text']]\n",
    "dedup_df['en_text'] = [re.sub(r\"<.*>\", \"\", x) for x in dedup_df['en_text']]\n",
    "dedup_df['jp_text'] = [re.sub(r\"\\（.*\\）\", \"\", x) for x in dedup_df['jp_text']]\n",
    "\n",
    "# Replacing \\\\N with \\n in en_texts\n",
    "dedup_df['en_text'] = dedup_df['en_text'].str.replace(r\"\\\\N\", \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strip \\n from the beginning of jp_text\n",
    "\n",
    "dedup_df['en_text'] = dedup_df['en_text'].str.strip()\n",
    "dedup_df['jp_text'] = dedup_df['jp_text'].str.strip()\n",
    "\n",
    "# Adding a new column type based on number of sentences in en_text and jp_text\n",
    "# Type 0 : If \"\\n\" in en_text and jp_text\n",
    "# Type 1 : If \"\\n\" in en_text but not in jp_text\n",
    "# Type 2 : If \"\\n\" in jp_text but not in en_text\n",
    "# Type 3 : No \"\\n\" in en_text and jp_text\n",
    "\n",
    "typ = []\n",
    "for i, row in dedup_df.iterrows():\n",
    "    if \"\\n\" in row['en_text'] and \"\\n\" in row['jp_text']:\n",
    "        typ.append(0)\n",
    "    elif \"\\n\" in row['en_text'] and \"\\n\" not in row['jp_text']:\n",
    "        typ.append(1)\n",
    "    elif \"\\n\" in row['jp_text'] and \"\\n\" not in row['en_text']:\n",
    "        typ.append(2)\n",
    "    else:\n",
    "        typ.append(3)\n",
    "        \n",
    "dedup_df['type'] = typ\n",
    "\n",
    "# Removing one word wrong translations \n",
    "\n",
    "dedup_df['en_text_words'] = dedup_df.en_text.apply(word_tokenize)\n",
    "dedup_df['word_count'] = dedup_df.en_text_words.apply(len)\n",
    "drop_df = dedup_df[operator.and_(dedup_df['word_count'] == 1, dedup_df['score'] != 1)]\n",
    "dedup_df = dedup_df.drop(drop_df.index)\n",
    "dedup_df = dedup_df.drop([\"en_text_words\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dedup_df.to_csv(\"dedup_df.csv\")\n",
    "dedup_df = pd.read_csv(\"dedup_df.csv\")\n",
    "dedup_df = dedup_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>en_text</th>\n",
       "      <th>jp_text</th>\n",
       "      <th>google_translated</th>\n",
       "      <th>score</th>\n",
       "      <th>semantic_score</th>\n",
       "      <th>file_name</th>\n",
       "      <th>type</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>It's that dream again.\\nJust who is that guy?</td>\n",
       "      <td>またあの夢だ　誰なんだ　あの人は</td>\n",
       "      <td>Another dream that is that dream</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.595040</td>\n",
       "      <td>07-Ghost-1.csv</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Chairman Miroku, I've heard that the level \\no...</td>\n",
       "      <td>ミロク理事長　今年の卒業生はレベルが高いと伺いましたぞ</td>\n",
       "      <td>Miroku President's graduates of this year have...</td>\n",
       "      <td>0.360000</td>\n",
       "      <td>0.834872</td>\n",
       "      <td>07-Ghost-1.csv</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>I'm going to fight for the empire and protect ...</td>\n",
       "      <td>俺　帝国のために戦って　家族を守ってみせる</td>\n",
       "      <td>I will fight for the empire and protect my family</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.624846</td>\n",
       "      <td>07-Ghost-1.csv</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>After my judgment, I was taken in by Miroku.\\n...</td>\n",
       "      <td>家族の愛情とか知らない</td>\n",
       "      <td>I do not know the loving of my family</td>\n",
       "      <td>0.260870</td>\n",
       "      <td>0.560514</td>\n",
       "      <td>07-Ghost-1.csv</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>If this guy is not defeated or if you \\nabando...</td>\n",
       "      <td>皆で力を合わせないと　本当にやられてしまいますよ</td>\n",
       "      <td>It will really be done if you all do not match...</td>\n",
       "      <td>0.217391</td>\n",
       "      <td>0.370212</td>\n",
       "      <td>07-Ghost-1.csv</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              en_text  \\\n",
       "0       It's that dream again.\\nJust who is that guy?   \n",
       "5   Chairman Miroku, I've heard that the level \\no...   \n",
       "11  I'm going to fight for the empire and protect ...   \n",
       "16  After my judgment, I was taken in by Miroku.\\n...   \n",
       "28  If this guy is not defeated or if you \\nabando...   \n",
       "\n",
       "                        jp_text  \\\n",
       "0              またあの夢だ　誰なんだ　あの人は   \n",
       "5   ミロク理事長　今年の卒業生はレベルが高いと伺いましたぞ   \n",
       "11        俺　帝国のために戦って　家族を守ってみせる   \n",
       "16                  家族の愛情とか知らない   \n",
       "28     皆で力を合わせないと　本当にやられてしまいますよ   \n",
       "\n",
       "                                    google_translated     score  \\\n",
       "0                    Another dream that is that dream  0.300000   \n",
       "5   Miroku President's graduates of this year have...  0.360000   \n",
       "11  I will fight for the empire and protect my family  0.363636   \n",
       "16              I do not know the loving of my family  0.260870   \n",
       "28  It will really be done if you all do not match...  0.217391   \n",
       "\n",
       "    semantic_score       file_name  type  word_count  \n",
       "0         0.595040  07-Ghost-1.csv     1          12  \n",
       "5         0.834872  07-Ghost-1.csv     1          22  \n",
       "11        0.624846  07-Ghost-1.csv     1          24  \n",
       "16        0.560514  07-Ghost-1.csv     1          25  \n",
       "28        0.370212  07-Ghost-1.csv     1          17  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type_one_df = dedup_df[dedup_df[\"type\"] == 1]\n",
    "type_one_df = type_one_df.drop('index', axis = 1)\n",
    "type_one_df = type_one_df.drop(['Unnamed: 0'], axis = 1)\n",
    "type_one_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ece9a7c152c4ab5847bbbc83d54d75f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=16913.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "type_one_split_list = []\n",
    "for i, row in tqdm(type_one_df.iterrows(), total = len(type_one_df)):\n",
    "    try:\n",
    "        first, second = row['en_text'].split(\"\\n\")\n",
    "    except:\n",
    "        continue\n",
    "    translated_text = row['google_translated']\n",
    "    file_name = row['file_name']\n",
    "    embeddings_translated = model.encode(translated_text, convert_to_tensor=True)\n",
    "    embeddings1 = model.encode(first, convert_to_tensor=True)\n",
    "    embeddings2 = model.encode(second, convert_to_tensor=True)\n",
    "    cosine_scores1 = util.pytorch_cos_sim(embeddings_translated, embeddings1)\n",
    "    cosine_scores2 = util.pytorch_cos_sim(embeddings_translated, embeddings2)\n",
    "    original_score = row['semantic_score']\n",
    "    translated_tokenized = word_tokenize(translated_text.lower())\n",
    "    \n",
    "    if cosine_scores1 > cosine_scores2 and cosine_scores1 > original_score:\n",
    "        en_tokenized = word_tokenize(first.lower())\n",
    "        score = jaccard(translated_tokenized, en_tokenized)\n",
    "        temp_list = [first, row['jp_text'], translated_text, score, cosine_scores1.item(), file_name, 3, len(en_tokenized)]\n",
    "        \n",
    "    elif cosine_scores2 > cosine_scores1 and cosine_scores2 > original_score:\n",
    "        en_tokenized = word_tokenize(second.lower())\n",
    "        score = jaccard(translated_tokenized, en_tokenized)\n",
    "        temp_list = [second, row['jp_text'], translated_text, score, cosine_scores2.item(),file_name, 3, len(en_tokenized)]\n",
    "        \n",
    "    else:\n",
    "        row[\"en_text\"] = row[\"en_text\"].replace(\"\\n\",\"\") \n",
    "        temp_list = list(row)\n",
    "        \n",
    "    type_one_split_list.append(temp_list)\n",
    "type_one_split_df = pd.DataFrame(type_one_split_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>en_text</th>\n",
       "      <th>jp_text</th>\n",
       "      <th>google_translated</th>\n",
       "      <th>score</th>\n",
       "      <th>semantic_score</th>\n",
       "      <th>file_name</th>\n",
       "      <th>type</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Are you crazy?</td>\n",
       "      <td>って お前ここ男子トイレだぞ\\nバッカじゃねえの？</td>\n",
       "      <td>You are a boy's toilet here\\nAren't you stupid?</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.277794</td>\n",
       "      <td>Accel_World-1.csv</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Um...</td>\n",
       "      <td>こんにちは\\n君…</td>\n",
       "      <td>Hello\\n ...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.462535</td>\n",
       "      <td>Accel_World-1.csv</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Accelerated?</td>\n",
       "      <td>加速？\\nそうだ</td>\n",
       "      <td>Accelerated?</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>Accel_World-1.csv</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>But this is your chance.</td>\n",
       "      <td>これはチャンスなのだよ\\nえっ？</td>\n",
       "      <td>This is a chance\\n?</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.674521</td>\n",
       "      <td>Accel_World-1.csv</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>It's a great chance.</td>\n",
       "      <td>おとなしく殴られますよ\\nせっかくのチャンスですから</td>\n",
       "      <td>I will be beaten\\nBecause it is a great opport...</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.405899</td>\n",
       "      <td>Accel_World-1.csv</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    en_text                     jp_text  \\\n",
       "0            Are you crazy?   って お前ここ男子トイレだぞ\\nバッカじゃねえの？   \n",
       "1                     Um...                   こんにちは\\n君…   \n",
       "2              Accelerated?                    加速？\\nそうだ   \n",
       "3  But this is your chance.            これはチャンスなのだよ\\nえっ？   \n",
       "4      It's a great chance.  おとなしく殴られますよ\\nせっかくのチャンスですから   \n",
       "\n",
       "                                   google_translated     score  \\\n",
       "0    You are a boy's toilet here\\nAren't you stupid?  0.272727   \n",
       "1                                        Hello\\n ...  0.333333   \n",
       "2                                       Accelerated?  1.000000   \n",
       "3                                This is a chance\\n?  0.375000   \n",
       "4  I will be beaten\\nBecause it is a great opport...  0.230769   \n",
       "\n",
       "   semantic_score          file_name  type  word_count  \n",
       "0        0.277794  Accel_World-1.csv     2           4  \n",
       "1        0.462535  Accel_World-1.csv     2           2  \n",
       "2        1.000000  Accel_World-1.csv     2           2  \n",
       "3        0.674521  Accel_World-1.csv     2           6  \n",
       "4        0.405899  Accel_World-1.csv     2           6  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dedup_df = pd.read_csv(\"dedup_df.csv\")\n",
    "dedup_df = dedup_df.dropna()\n",
    "#clean_type_2_df = pd.read_csv(\"type_2.csv\")\n",
    "type_two_df = dedup_df[dedup_df[\"type\"] == 2]\n",
    "type_two_df = type_two_df.reset_index()\n",
    "type_two_df = type_two_df.drop('index', axis = 1)\n",
    "type_two_df = type_two_df.drop(['Unnamed: 0'], axis = 1)\n",
    "type_two_df = type_two_df.drop(['level_0'], axis = 1)\n",
    "type_two_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aec956e193b94e36881ec6bd798c24f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=85600.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "type_two_split_list = []\n",
    "no = 0\n",
    "for i, row in tqdm(type_two_df.iterrows(), total = len(type_two_df)):\n",
    "    #if i < 25800:\n",
    "    #    continue\n",
    "    #try:\n",
    "    #    first, second = row['jp_text'].split(\"\\n\")\n",
    "    #except:\n",
    "    #    continue\n",
    "    #while True:\n",
    "    #    try:\n",
    "    #        first_translated_text = translator.translate(first, dest = \"en\", src=\"ja\").text\n",
    "    #        second_translated_text = translator.translate(second, dest = \"en\", src=\"ja\").text\n",
    "    #        break\n",
    "    #    except:\n",
    "    #        continue\n",
    "    try:\n",
    "        first_translated_text, second_translated_text = row['google_translated'].split(\"\\n\")\n",
    "        first, second = row['jp_text'].split(\"\\n\")\n",
    "    except:\n",
    "        continue\n",
    "    en_text = row['en_text']\n",
    "    file_name = row['file_name']\n",
    "    embeddings_text = model.encode(en_text, convert_to_tensor=True)\n",
    "    embeddings1 = model.encode(first_translated_text, convert_to_tensor=True)\n",
    "    embeddings2 = model.encode(second_translated_text, convert_to_tensor=True)\n",
    "    cosine_scores1 = util.pytorch_cos_sim(embeddings_text, embeddings1)\n",
    "    cosine_scores2 = util.pytorch_cos_sim(embeddings_text, embeddings2)\n",
    "    original_score = row['semantic_score']\n",
    "    en_tokenized = word_tokenize(en_text.lower())\n",
    "    \n",
    "    if cosine_scores1 > cosine_scores2 and cosine_scores1 > original_score:\n",
    "        first_tokenized = word_tokenize(first_translated_text.lower())\n",
    "        score = jaccard(first_tokenized, en_tokenized)\n",
    "        temp_list = [row['en_text'], first, first_translated_text, score, cosine_scores1.item(),file_name, 3, len(en_tokenized)]\n",
    "        \n",
    "    elif cosine_scores2 > cosine_scores1 and cosine_scores2 > original_score:\n",
    "        second_tokenized = word_tokenize(second_translated_text.lower())\n",
    "        score = jaccard(second_tokenized, en_tokenized)\n",
    "        temp_list = [row['en_text'], second, second_translated_text, score, cosine_scores2.item(), file_name, 3, len(en_tokenized)]\n",
    "        \n",
    "    else:\n",
    "        row[\"jp_text\"] = row[\"jp_text\"].replace(\"\\n\",\"\") \n",
    "        temp_list = list(row)\n",
    "        \n",
    "    type_two_split_list.append(temp_list)\n",
    "    \n",
    "    #if (len(type_two_split_list) + 1) % 100 == 0:\n",
    "    #    no += 1\n",
    "    #    type_two_split_df = pd.DataFrame(type_two_split_list)\n",
    "    #    type_two_split_df.to_csv(\"type_2_\"+str(no)+\".csv\")\n",
    "    #    type_two_split_list = []\n",
    "    \n",
    "type_two_split_df = pd.DataFrame(type_two_split_list)\n",
    "no += 1\n",
    "type_two_split_df.to_csv(\"type_2_\"+str(no)+\".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_three_df = dedup_df[dedup_df[\"type\"] == 3]\n",
    "type_three_df = type_three_df.drop(['index','Unnamed: 0'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_one_split_df.columns = type_three_df.columns\n",
    "type_two_split_df.columns = type_three_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(475038, 8)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df = pd.concat([type_one_split_df, type_two_split_df, type_three_df], axis = 0)\n",
    "clean_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df.to_csv(\"clean_tl_dataset.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>en_text</th>\n",
       "      <th>jp_text</th>\n",
       "      <th>google_translated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>249842</th>\n",
       "      <td>My cigarette says that one.</td>\n",
       "      <td>俺のタバコは あの店を選んだぜ</td>\n",
       "      <td>My cigarette chose that store</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149436</th>\n",
       "      <td>What is the one thing I don't want to let go?</td>\n",
       "      <td>手放したくないもんはどれ？</td>\n",
       "      <td>Which do you don't want to let go?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338844</th>\n",
       "      <td>I can't move at all.</td>\n",
       "      <td>まったく 何やってるんだ</td>\n",
       "      <td>I'm doing anything at all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389797</th>\n",
       "      <td>I'll defeat Kaito, Rook, and all you freaks. T...</td>\n",
       "      <td>カイトもルークも　全員ぶっ倒し 俺がファイ・ブレインになる。</td>\n",
       "      <td>All kites and Luke are tired and I become a fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258835</th>\n",
       "      <td>Write \"contradiction\" three times. contradiction</td>\n",
       "      <td>三回ずつ書け</td>\n",
       "      <td>Write three times</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  en_text  \\\n",
       "249842                        My cigarette says that one.   \n",
       "149436      What is the one thing I don't want to let go?   \n",
       "338844                               I can't move at all.   \n",
       "389797  I'll defeat Kaito, Rook, and all you freaks. T...   \n",
       "258835   Write \"contradiction\" three times. contradiction   \n",
       "\n",
       "                               jp_text  \\\n",
       "249842                 俺のタバコは あの店を選んだぜ   \n",
       "149436                   手放したくないもんはどれ？   \n",
       "338844                    まったく 何やってるんだ   \n",
       "389797  カイトもルークも　全員ぶっ倒し 俺がファイ・ブレインになる。   \n",
       "258835                          三回ずつ書け   \n",
       "\n",
       "                                        google_translated  \n",
       "249842                      My cigarette chose that store  \n",
       "149436                 Which do you don't want to let go?  \n",
       "338844                          I'm doing anything at all  \n",
       "389797  All kites and Luke are tired and I become a fi...  \n",
       "258835                                  Write three times  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df.sample(5)[['en_text','jp_text','google_translated']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep",
   "language": "python",
   "name": "deep"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
